{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Tensorflow\n",
    "\n",
    "from the Udacity Deep Learning [Nanodegree](http://udacity.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coding the Linear Function in Tensorlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to initialize the Variable in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tf.global_variables_initializer() call returns an operation that will initialize all TensorFlow variables from the graph. You call the operation using a session to initialize all the variables as shown above. Using the tf.Variable class allows us to change the weights and bias, but an initial value needs to be chosen.\n",
    "\n",
    "Initializing the weights with random numbers from a normal distribution is good practice. Randomizing the weights helps the model from becoming stuck in the same place every time you train it. You'll learn more about this in the next lesson, when you study gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_features = 120\n",
    "n_labels = 5\n",
    "weights = tf.Variable(tf.truncated_normal((n_features, n_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tf.truncated_normal() function returns a tensor with random values from a normal distribution whose magnitude is no more than 2 standard deviations from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the Bias to 0\n",
    "bias = tf.Variable(tf.zeros(n_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Linear Classifier on the DIGITS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the necessary class\n",
    "class linear_classifier(object):\n",
    "    \n",
    "    def __init__(self, input):\n",
    "        self.features = input[:,0]\n",
    "        self.labels = input[:, 1]\n",
    "        self.n_features = len(self.features[0])\n",
    "        self.n_labels = len(self.labels[0])\n",
    "        \n",
    "        \n",
    "    def get_weights(self):\n",
    "        self.weights = tf.Variable(tf.truncated_normal((self.n_features, self.n_labels)))\n",
    "    \n",
    "    def get_biases(self):\n",
    "        self.biases = tf.Variable(tf.zeros(n_labels))\n",
    "    \n",
    "    def calculate_linear(self):\n",
    "        self.logits = tf.add(tf.matmul(self.features, self.weights), self.biases)\n",
    "    \n",
    "    def fit(self):\n",
    "        # Set the values\n",
    "        self.get_weights()\n",
    "        self.get_biases()\n",
    "        self.calculate_linear()\n",
    "        \n",
    "        # Create Train Test split\n",
    "        train_features, train_labels = train_test_split(self.features, self.labels)\n",
    "        \n",
    "        # run the session\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            # Run a softmax layer\n",
    "            prediction = tf.nn.softmax(logits)\n",
    "            \n",
    "            # Calculate the loss function (cross entropy)\n",
    "            cross_entropy = -tf.reduce_sum(self.labels * tf.log(prediction), reduction_indices=1)\n",
    "            \n",
    "            # Calculate the loss\n",
    "            loss = tf.reduce_mean(cross_entropy)\n",
    "            \n",
    "            learning_rate = 0.08\n",
    "            \n",
    "            # Run optimizer and get loss\n",
    "            _, l = session.run(\n",
    "                [optimizer, loss],\n",
    "                feed_dict = {features: train_features, labels: train_labels}\n",
    "            )\n",
    "            \n",
    "        return \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Flow Softmax Implemementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.65900117  0.24243298  0.09856589]\n"
     ]
    }
   ],
   "source": [
    "def run(logit_data):\n",
    "    output = None\n",
    "    logits = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # Calculate the softmax of the logits\n",
    "    softmax = tf.nn.softmax(logits)\n",
    "    \n",
    "    # Run the model\n",
    "    with tf.Session() as sess:\n",
    "        output = sess.run(softmax, feed_dict={logits: logit_data})\n",
    "        \n",
    "    return output\n",
    "\n",
    "print(run([2.0, 1.0, 0.1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding\n",
    "\n",
    "Using the softmax representation of propabilities for a given class in prediction, we can design our input to represent the correct answer for our training examples in the same way.\n",
    "\n",
    "We set the correct class to have propability of 1 and all others to have propability 0.\n",
    "\n",
    "The resulting encoding is called a **one-hot vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementing one hot enconding using scikit learn\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Example labels\n",
    "labels = np.array([1,5,3,2,4,3,2,1])\n",
    "\n",
    "# Creating the encoder\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "# Fit the encoder to the classes and create one-hot vecrotsx \n",
    "lb.fit(labels)\n",
    "\n",
    "# Transform labels to one hot encoded vectors\n",
    "lb.transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function for multiple categorical classification\n",
    "\n",
    "Where we previously used the sum-of-squares-error function to calculate the cost function, we now have to calculate the error for an output vector (softmax non-linearity)\n",
    "\n",
    "We want to be the error in proportion to the distance between the one-hot-vector (label) and our softmax-vector.\n",
    "This distance is calculated using cross-entropy. \n",
    "\n",
    "Its calculated as the **sum of the distance of the label times the natural log of the prediction propabilities**.\n",
    "\n",
    "As all functions cancel because of the 0 in the one-hot-vector, we can reformulate this solution to the product of the natural log of the predicted propability at the correct class and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Core Tensorflow functions\n",
    "x = tf.reduce_sum([1,2,3,4,5])\n",
    "x = tf.log(100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.356675\n"
     ]
    }
   ],
   "source": [
    "# Implementing the Cross Entropy\n",
    "softmax_data = [0.7, 0.2, 0.1]\n",
    "one_hot_data = [1.0, 0.0, 0.0]\n",
    "\n",
    "softmax = tf.placeholder(tf.float32)\n",
    "one_hot = tf.placeholder(tf.float32)\n",
    "\n",
    "# Calculating the Cross Entropy function\n",
    "cross_entropy = -tf.reduce_sum(tf.multiply(one_hot, tf.log(softmax)))\n",
    "\n",
    "# Running it\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(cross_entropy, feed_dict={\n",
    "        softmax: softmax_data,\n",
    "        one_hot: one_hot_data\n",
    "    }))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Mini-Batching\" to train on subsets of data in large Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batches(batch_size, features, labels):\n",
    "    # Check for same length on input variables\n",
    "    assert len(features) == len(labels)\n",
    "    \n",
    "    output_batches = []\n",
    "    sample_size = len(features)\n",
    "    for start_i in range(0, sample_size, batch_size):\n",
    "        end_i = start_i + batch_size\n",
    "        batch = [features[start_i:end_i], labels[start_i:end_i]]\n",
    "        output_batches.append(batch)\n",
    "    \n",
    "    return output_batches\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4 Samples of features\n",
    "example_features = [\n",
    "    ['F11','F12','F13','F14'],\n",
    "    ['F21','F22','F23','F24'],\n",
    "    ['F31','F32','F33','F34'],\n",
    "    ['F41','F42','F43','F44']]\n",
    "# 4 Samples of labels\n",
    "example_labels = [\n",
    "    ['L11','L12'],\n",
    "    ['L21','L22'],\n",
    "    ['L31','L32'],\n",
    "    ['L41','L42']]\n",
    "\n",
    "\n",
    "\n",
    "example_batches = batches(3, example_features, example_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[['F11', 'F12', 'F13', 'F14'],\n",
       "   ['F21', 'F22', 'F23', 'F24'],\n",
       "   ['F31', 'F32', 'F33', 'F34']],\n",
       "  [['L11', 'L12'], ['L21', 'L22'], ['L31', 'L32']]],\n",
       " [[['F41', 'F42', 'F43', 'F44']], [['L41', 'L42']]]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent\n",
    "\n",
    "Implementin g a scalable and performant solution to apply gradient descent optimization to large Models with large Amounts of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /datasets/ud730/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting /datasets/ud730/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting /datasets/ud730/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /datasets/ud730/mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Loading the Data into the Model\n",
    "mnist = input_data.read_data_sets('/datasets/ud730/mnist', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Splitting the Data\n",
    "train_features = mnist.train.images\n",
    "test_features = mnist.test.images\n",
    "\n",
    "train_labels = mnist.train.labels.astype(np.float32)\n",
    "test_labels = mnist.test.labels.astype(np.float32)\n",
    "\n",
    "# Setting Hyperparameter for batch training on s.g.d\n",
    "learn_rate = 0.001\n",
    "batch_size = 128\n",
    "\n",
    "# Setting weights and bias\n",
    "n_input = train_features.shape[1]\n",
    "n_classes = train_labels.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Features and Labeles\n",
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Weights and biases\n",
    "weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Logits - xW + b\n",
    "logits = tf.add(tf.matmul(features, weights), bias)\n",
    "\n",
    "# Define loss and optimizer\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runing the stochastic Gradient on batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model on Epochs\n",
    "\n",
    "An Epoch is a single forward and backward propagation trough the whole training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_epoch_stats(epch_i, sess, last_features, last_labels):\n",
    "    current_cost = sess.run(\n",
    "        cost, \n",
    "        feed_dict={features: last_features, labels: last_labels})\n",
    "    valid_accuracy = sess.run(\n",
    "        accuracy, \n",
    "        feed_dict={features: valid_features, labels: valid_labels})\n",
    "    print('Epoch: {:<4} - Cost: {:<8.3} Valid Accuracy'.format(\n",
    "        epoch_i,\n",
    "        current_cost,\n",
    "        valid_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the number of epochs\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Blas GEMM launch failed : a.shape=(128, 784), b.shape=(784, 10), m=128, n=10, k=784\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_Placeholder_0/_7, Variable/read)]]\n\nCaused by op 'MatMul', defined at:\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2683, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2787, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2847, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-1a3f7655897e>\", line 2, in <module>\n    logits = tf.add(tf.matmul(features, weights), bias)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1801, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 1263, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(128, 784), b.shape=(784, 10), m=128, n=10, k=784\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_Placeholder_0/_7, Variable/read)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(128, 784), b.shape=(784, 10), m=128, n=10, k=784\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_Placeholder_0/_7, Variable/read)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-cc25e2161bfc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# Train optimizer on all batches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint_epoch_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(128, 784), b.shape=(784, 10), m=128, n=10, k=784\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_Placeholder_0/_7, Variable/read)]]\n\nCaused by op 'MatMul', defined at:\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2683, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2787, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2847, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-1a3f7655897e>\", line 2, in <module>\n    logits = tf.add(tf.matmul(features, weights), bias)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1801, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 1263, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\frank\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(128, 784), b.shape=(784, 10), m=128, n=10, k=784\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_Placeholder_0/_7, Variable/read)]]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Training Cycle trough the epochs\n",
    "    for epoch_i in range(epochs):\n",
    "        \n",
    "        # Train optimizer on all batches\n",
    "        for batch_features, batch_labels in batches(batch_size, train_features, train_labels):\n",
    "            sess.run(optimizer, feed_dict={features: batch_features, labels: batch_labels, learning_rate: learn_rate})\n",
    "            \n",
    "    print_epoch_stats(epoch_i, sess, batch_features, batch_labels)\n",
    "    \n",
    "    # Calculate accuracy for test dataset\n",
    "    test_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={features: test_features, labels: test_labels})\n",
    "    \n",
    "print('Test Accuracy: {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement \"S.G.D\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing \"Learning Rate Decay\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing \"Momentum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu]",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
